{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0767441",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.129106Z",
     "iopub.status.busy": "2022-01-14T00:42:30.127327Z",
     "iopub.status.idle": "2022-01-14T00:42:30.149979Z",
     "shell.execute_reply": "2022-01-14T00:42:30.150654Z",
     "shell.execute_reply.started": "2022-01-13T23:46:24.815024Z"
    },
    "papermill": {
     "duration": 0.042534,
     "end_time": "2022-01-14T00:42:30.150986",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.108452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datamanipulationwithpandas/temperatures.csv\n",
      "/kaggle/input/datamanipulationwithpandas/homelessness.csv\n",
      "/kaggle/input/datamanipulationwithpandas/sales_subset.csv\n",
      "/kaggle/input/datamanipulationwithpandas/avoplotto.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185c8366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.185322Z",
     "iopub.status.busy": "2022-01-14T00:42:30.184497Z",
     "iopub.status.idle": "2022-01-14T00:42:30.250122Z",
     "shell.execute_reply": "2022-01-14T00:42:30.250687Z",
     "shell.execute_reply.started": "2022-01-14T00:00:55.787210Z"
    },
    "papermill": {
     "duration": 0.086111,
     "end_time": "2022-01-14T00:42:30.250864",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.164753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>store</th>\n",
       "      <th>type</th>\n",
       "      <th>department</th>\n",
       "      <th>date</th>\n",
       "      <th>weekly_sales</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature_c</th>\n",
       "      <th>fuel_price_usd_per_l</th>\n",
       "      <th>unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>5.727778</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>8.055556</td>\n",
       "      <td>0.693452</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-04-02</td>\n",
       "      <td>57258.43</td>\n",
       "      <td>False</td>\n",
       "      <td>16.816667</td>\n",
       "      <td>0.718284</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>17413.94</td>\n",
       "      <td>False</td>\n",
       "      <td>22.527778</td>\n",
       "      <td>0.748928</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-04</td>\n",
       "      <td>17558.09</td>\n",
       "      <td>False</td>\n",
       "      <td>27.050000</td>\n",
       "      <td>0.714586</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
       "0           0      1    A           1  2010-02-05      24924.50       False   \n",
       "1           1      1    A           1  2010-03-05      21827.90       False   \n",
       "2           2      1    A           1  2010-04-02      57258.43       False   \n",
       "3           3      1    A           1  2010-05-07      17413.94       False   \n",
       "4           4      1    A           1  2010-06-04      17558.09       False   \n",
       "\n",
       "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
       "0       5.727778              0.679451         8.106  \n",
       "1       8.055556              0.693452         8.106  \n",
       "2      16.816667              0.718284         7.808  \n",
       "3      22.527778              0.748928         7.808  \n",
       "4      27.050000              0.714586         7.808  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv(\"/kaggle/input/datamanipulationwithpandas/sales_subset.csv\")\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a24fe",
   "metadata": {
    "papermill": {
     "duration": 0.013,
     "end_time": "2022-01-14T00:42:30.277041",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.264041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**What percent of sales occurred at each store type?**\n",
    "\n",
    "While .groupby() is useful, you can calculate grouped summary statistics without it.\n",
    "\n",
    "Walmart distinguishes three types of stores: \"supercenters,\" \"discount stores,\" and \"neighborhood markets,\" encoded in this dataset as type \"A,\" \"B,\" and \"C.\" In this exercise, you'll calculate the total sales made at each store type, without using .groupby(). You can then use these numbers to see what proportion of Walmart's total sales were made at each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052e98be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.308478Z",
     "iopub.status.busy": "2022-01-14T00:42:30.307490Z",
     "iopub.status.idle": "2022-01-14T00:42:30.332936Z",
     "shell.execute_reply": "2022-01-14T00:42:30.333975Z",
     "shell.execute_reply.started": "2022-01-14T00:04:53.070379Z"
    },
    "papermill": {
     "duration": 0.04411,
     "end_time": "2022-01-14T00:42:30.334322",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.290212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233716315.01\n"
     ]
    }
   ],
   "source": [
    "# Calc total weekly sales\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Print sales for type A\n",
    "print(sales_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c5924",
   "metadata": {
    "papermill": {
     "duration": 0.013344,
     "end_time": "2022-01-14T00:42:30.362684",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.349340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Calculations with .groupby()**\n",
    "\n",
    "The .groupby() method makes life much easier. In this exercise, you'll perform the same calculations as last time, except you'll use the .groupby() method. You'll also perform calculations on data grouped by two variables to see if sales differ by store type depending on if it's a holiday week or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c6c2ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.402740Z",
     "iopub.status.busy": "2022-01-14T00:42:30.393970Z",
     "iopub.status.idle": "2022-01-14T00:42:30.409560Z",
     "shell.execute_reply": "2022-01-14T00:42:30.408924Z",
     "shell.execute_reply.started": "2022-01-14T00:07:24.883480Z"
    },
    "papermill": {
     "duration": 0.033348,
     "end_time": "2022-01-14T00:42:30.409748",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.376400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.909775\n",
      "B    0.090225\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by type; calc total weekly sales\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = sales_by_type / sum(sales_by_type)\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697a861",
   "metadata": {
    "papermill": {
     "duration": 0.014417,
     "end_time": "2022-01-14T00:42:30.438691",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.424274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Multiple grouped summaries**\n",
    "\n",
    "The .agg() method is useful to compute multiple statistics on multiple variables. It also works with grouped data. NumPy has many different summary statistics functions, including: np.min, np.max, np.mean, and np.median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d3d6bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.471501Z",
     "iopub.status.busy": "2022-01-14T00:42:30.470793Z",
     "iopub.status.idle": "2022-01-14T00:42:30.510008Z",
     "shell.execute_reply": "2022-01-14T00:42:30.510607Z",
     "shell.execute_reply.started": "2022-01-14T00:09:52.701629Z"
    },
    "papermill": {
     "duration": 0.057421,
     "end_time": "2022-01-14T00:42:30.510820",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.453399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        amin       amax          mean    median\n",
      "type                                           \n",
      "A    -1098.0  293966.05  23674.667242  11943.92\n",
      "B     -798.0  232558.51  25696.678370  13336.08\n",
      "     unemployment                         fuel_price_usd_per_l            \\\n",
      "             amin   amax      mean median                 amin      amax   \n",
      "type                                                                       \n",
      "A           3.879  8.992  7.972611  8.067             0.664129  1.107410   \n",
      "B           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n",
      "\n",
      "                          \n",
      "          mean    median  \n",
      "type                      \n",
      "A     0.744619  0.735455  \n",
      "B     0.805858  0.803348  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Import numpy with the alias np\n",
    "import numpy as np\n",
    "\n",
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[\"unemployment\", \"fuel_price_usd_per_l\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a788c13",
   "metadata": {
    "papermill": {
     "duration": 0.01453,
     "end_time": "2022-01-14T00:42:30.540157",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.525627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Pivoting on one variable**\n",
    "\n",
    "Pivot tables are the standard way of aggregating data in spreadsheets. In pandas, pivot tables are essentially just another way of performing grouped calculations. That is, the .pivot_table() method is just an alternative to .groupby().\n",
    "\n",
    "In this exercise, you'll perform calculations using .pivot_table() to replicate the calculations you performed in the last lesson using .groupby()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45feab22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.577253Z",
     "iopub.status.busy": "2022-01-14T00:42:30.576564Z",
     "iopub.status.idle": "2022-01-14T00:42:30.587609Z",
     "shell.execute_reply": "2022-01-14T00:42:30.586689Z",
     "shell.execute_reply.started": "2022-01-14T00:18:39.856879Z"
    },
    "papermill": {
     "duration": 0.032918,
     "end_time": "2022-01-14T00:42:30.587830",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.554912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weekly_sales\n",
      "type              \n",
      "A     23674.667242\n",
      "B     25696.678370\n"
     ]
    }
   ],
   "source": [
    "# Get the mean weekly_sales by type using .pivot_table() and store as mean_sales_by_type.\n",
    "# Pivot for mean weekly_sales for each store type\n",
    "mean_sales_by_type = sales.pivot_table(values = \"weekly_sales\", index = \"type\")\n",
    "\n",
    "# Print mean_sales_by_type\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c3de69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.625702Z",
     "iopub.status.busy": "2022-01-14T00:42:30.622227Z",
     "iopub.status.idle": "2022-01-14T00:42:30.645214Z",
     "shell.execute_reply": "2022-01-14T00:42:30.644397Z",
     "shell.execute_reply.started": "2022-01-14T00:20:32.807539Z"
    },
    "papermill": {
     "duration": 0.041222,
     "end_time": "2022-01-14T00:42:30.645419",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.604197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean       median\n",
      "      weekly_sales weekly_sales\n",
      "type                           \n",
      "A     23674.667242     11943.92\n",
      "B     25696.678370     13336.08\n"
     ]
    }
   ],
   "source": [
    "# Get the mean and median (using NumPy functions) of weekly_sales by type using .pivot_table() and store as mean_med_sales_by_type\n",
    "\n",
    "# Import NumPy as np\n",
    "import numpy as np\n",
    "\n",
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(values = \"weekly_sales\", index = \"type\", aggfunc = [np.mean, np.median])\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f94b6619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.685524Z",
     "iopub.status.busy": "2022-01-14T00:42:30.682727Z",
     "iopub.status.idle": "2022-01-14T00:42:30.707567Z",
     "shell.execute_reply": "2022-01-14T00:42:30.706856Z",
     "shell.execute_reply.started": "2022-01-14T00:21:26.610137Z"
    },
    "papermill": {
     "duration": 0.046148,
     "end_time": "2022-01-14T00:42:30.707739",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.661591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday         False       True\n",
      "type                               \n",
      "A           23768.583523  590.04525\n",
      "B           25751.980533  810.70500\n"
     ]
    }
   ],
   "source": [
    "# Get the mean of weekly_sales by type and is_holiday using .pivot_table() and store as mean_sales_by_type_holiday\n",
    "\n",
    "# Pivot for mean weekly_sales by store type and holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(values = \"weekly_sales\", index = \"type\", columns = \"is_holiday\")\n",
    "\n",
    "# Print mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d2314",
   "metadata": {
    "papermill": {
     "duration": 0.015607,
     "end_time": "2022-01-14T00:42:30.739219",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.723612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Fill in missing values and sum values with pivot tables**\n",
    "\n",
    "The .pivot_table() method has several useful arguments, including fill_value and margins.\n",
    "\n",
    "fill_value replaces missing values with a real value (known as imputation). What to replace missing values with is a topic big enough to have its own blog, but the simplest thing to do is to substitute a dummy value.\n",
    "margins is a shortcut for when you pivoted by two variables, but also wanted to pivot by each of those variables separately: it gives the row and column totals of the pivot table contents.\n",
    "Let's practice using these arguments to up your pivot table skills, which will help you crunch numbers more efficiently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012eafb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.777208Z",
     "iopub.status.busy": "2022-01-14T00:42:30.776522Z",
     "iopub.status.idle": "2022-01-14T00:42:30.796085Z",
     "shell.execute_reply": "2022-01-14T00:42:30.795075Z",
     "shell.execute_reply.started": "2022-01-14T00:23:40.985661Z"
    },
    "papermill": {
     "duration": 0.041255,
     "end_time": "2022-01-14T00:42:30.796305",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.755050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                    A              B\n",
      "department                              \n",
      "1            30961.725379   44050.626667\n",
      "2            67600.158788  112958.526667\n",
      "3            17160.002955   30580.655000\n",
      "4            44285.399091   51219.654167\n",
      "5            34821.011364   63236.875000\n",
      "...                   ...            ...\n",
      "95          123933.787121   77082.102500\n",
      "96           21367.042857    9528.538333\n",
      "97           28471.266970    5828.873333\n",
      "98           12875.423182     217.428333\n",
      "99             379.123659       0.000000\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(sales.pivot_table(values = \"weekly_sales\", index = \"department\", columns = \"type\", fill_value = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb4a611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T00:42:30.838573Z",
     "iopub.status.busy": "2022-01-14T00:42:30.835043Z",
     "iopub.status.idle": "2022-01-14T00:42:30.879554Z",
     "shell.execute_reply": "2022-01-14T00:42:30.877751Z",
     "shell.execute_reply.started": "2022-01-14T00:24:28.168897Z"
    },
    "papermill": {
     "duration": 0.066683,
     "end_time": "2022-01-14T00:42:30.879831",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.813148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                   A              B           All\n",
      "department                                           \n",
      "1           30961.725379   44050.626667  32052.467153\n",
      "2           67600.158788  112958.526667  71380.022778\n",
      "3           17160.002955   30580.655000  18278.390625\n",
      "4           44285.399091   51219.654167  44863.253681\n",
      "5           34821.011364   63236.875000  37189.000000\n",
      "...                  ...            ...           ...\n",
      "96          21367.042857    9528.538333  20337.607681\n",
      "97          28471.266970    5828.873333  26584.400833\n",
      "98          12875.423182     217.428333  11820.590278\n",
      "99            379.123659       0.000000    379.123659\n",
      "All         23674.667242   25696.678370  23843.950149\n",
      "\n",
      "[81 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols\n",
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"department\", columns=\"type\", fill_value = 0, margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f2b48",
   "metadata": {
    "papermill": {
     "duration": 0.016172,
     "end_time": "2022-01-14T00:42:30.912775",
     "exception": false,
     "start_time": "2022-01-14T00:42:30.896603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.568863,
   "end_time": "2022-01-14T00:42:31.641478",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-14T00:42:19.072615",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
